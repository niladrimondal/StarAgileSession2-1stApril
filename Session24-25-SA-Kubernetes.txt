Kubernetes Cluster:
Which is going to work as a Orchastration tool, Multiple nodes

1. k8s - you can install the same in VM 
2. You can use the managed cloud services/ Minikube / Kubeadm 
EKS , AKS , GKE

+++++++++++++++++++++++++++++++++++++++++
minikube kubectl -- get pods -A
   20  alias kubectl="minikube kubectl --"
   21  kubectl get pods
   24  kubectl run nginx --image="nginx"
   25  kubectl get pods
   26  kubectl get nodes
   27  kubectl explain pods
   28  kubectl get pods
   31  minikube kubectl get pods
   32  minikube kubectl explain pods
   
   37  minikube kubectl create -f pod.yaml
   38  minikube kubectl create -- -f pod.yaml
   39  minikube kubectl delete pods nginx
   40  minikube kubectl create -- -f pod.yaml
   41  minikube kubectl describe pods nginx
   42  clearf
   43  clear
   44  vi sample.yml
   45  clear
   46  minikube kubectl create -- -f sample.yml
   47  vi sample.yml
   48  minikube kubectl create -- -f sample.yml
   49  vi sample.yml
   50  minikube kubectl get pods
   51  vi pod.yaml
   52  minikube kubectl apply  -- -f sample.yml
   53  minikube kubectl apply  -- -f pod.yaml
   54  clear
   55  minikube kubectl get pods
   56  minikube kubectl describe pods nginx
   
minikube kubectl -- get pods -A
minikube kubectl get ns
minikube kubectl get nodes
minikube kubectl create ns niladri
minikube kubectl create -- -f pod.yaml
minikube kubectl get pods -- -n niladri -o wide


121  alias kubectl="minikube kubectl --"
  122  kubectl get deployments
  123  kubectl rollout status deployment/nginx-deployment
  124  kubectl get rs
  125  kubectl get pods --show-lables
  126  kubectl get pods -- --show-lables
  127  kubectl get pods -- --show-labels
  128  kubectl get pods --show-labels
  129  clear
  130  cat deployment-nginx.yaml
  131  clear
  132  ls
  133  clear
  Rollout and RollBack
  134  kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1
  135  kubectl rollout status deployment/nginx-deployment
  136  kubectl get deployment
  137  kubectl get rs
  138  kubectl describe deployment nginx-deployment
  143  kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.161
  144  kubectl rollout status deployment/nginx-deployment
  145  kubectl get rs
  146  kubectl rollout status deployment/nginx-deployment
  147  clear
  148  kubectl get pods
  149  kubectl rollout history deployment/nginx-deployment
  157  kubectl rollout history deployment/nginx-deployment --revision=3
  158  clear
  159  kubectl rollout history deployment/nginx-deployment --revision=2
  160  kubectl rollout history deployment/nginx-deployment --revision=1
  163  kubectl rollout undo deployment/nginx-deployment

Autoscale: 
  175  kubectl scale deployment/nginx-deployment --replicas=7
  176  kubectl get rs
  177  kubectl autoscale deployment/nginx-deployment --min=4 --max=10 --cpu-percent=80


++++++++++++++++++++++++++++++
##########multiple container in a single pod:
#Now I am going to create my pod
nano sample.yml

apiVersion: v1
kind: Pod
metadata:
  name: multi-container
spec:
  terminationGracePeriodSeconds: 0
  containers:
  - name: nginx
    image: nginx:1.10-alpine
	ports:
	- containerPort: 80
  - name: alpine
    image: alpine:3.5
	command: ["watch","wget","-qO-","localhost"]
	
#create a single container pod
kubectl run tomcat --image=tomcat:8.0
#output
$ kubectl run tomcat --image=tomcat:8.0
pod/tomcat created
amrutagosavi76a@ip-172-31-21-114:~$ kubectl get pods
NAME              READY   STATUS    RESTARTS   AGE
multi-container   2/2     Running   0          17m
tomcat            1/1     Running   0          59s
amrutagosavi76a@ip-172-31-21-114:~$ 

++++++++++++++++++++++++++++++
You can setup the pods in different way
either using the adhoc command or you can use manifest file, written in yaml

++++++++++++++++++++++++++++++++++++++++++++
Master componets:
Kube-api server
Kube- scheduler
Kube-control-manager
etcd 

Worker :
kubelet
kube-proxy
container runtime
pods
++++++++++++++++++++++++
pods:
https://kubernetes.io/docs/concepts/workloads/pods/

Replicaset:
https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/

Deployment:
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/

Service: 
https://kubernetes.io/docs/concepts/services-networking/service/
++++++++++++++++++++++++
Deploy Addressbook through Minikube:

Create Deployment:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: addressbook-deployment
  labels:
    app: addressbook
spec:
  replicas: 3
  selector:
    matchLabels:
      app: addressbook
  template:
    metadata:
      labels:
        app: addressbook
    spec:
      containers:
      - name: addressbook
        image: niladrimondaldcr/addressbook:1.0
        ports:
        - containerPort: 8080
		
Create Service:
apiVersion: v1
kind: Service
metadata:
  name: address-service
spec:
  type: NodePort
  selector:
    app: addressbook
  ports:
      # By default and for convenience, the `targetPort` is set to the same value as the `port` field.
    - port: 8080
      targetPort: 8080
      # Optional field
      # By default and for convenience, the Kubernetes control plane will allocate a port from a range (default: 30000-32767)
      nodePort: 30007

It may take a moment, but your deployment will soon show up when you run:
kubectl get services address-service

The easiest way to access this service is to let minikube launch a web browser for you:
minikube service address-service

Alternatively, use kubectl to forward the port:
kubectl port-forward service/hello-minikube 7080:8080

curl http://192.168.49.2:30007/addressbook/

+++++++++++++++++++++++++++++++++++++++++++++++++++
Deploy Using Kubeadm
###########################################################################################
install kubedm,kubectl(not required for worker node),kubelet

https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl

sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg

echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl


kubelet --version
kubeadm version
kubectl version --client

#fix the docker issue
sudo nano /etc/docker/daemon.json

{
  "exec-opts": ["native.cgroupdriver=systemd"]
}

sudo systemctl restart docker

#containerd 
sudo systemctl status containerd
sudo nano /etc/containerd/config.toml
#disabled_plugins = ["cri"]
sudo systemctl restart containerd

#if required you can uprade the kubernetes version
sudo apt-get upgrade kubelet kubeadm kubectl
++++++++++++++++++++++++++++++++++++++++++

#initialize the k8's cluster
sudo kubeadm init --pod-network-cidr=10.244.0.0/16

#partial output of the above command
Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 172.31.21.114:6443 --token k4mulx.fap2kvzlr4734fjd \
	--discovery-token-ca-cert-hash sha256:39e7ccb8bdd08b66fae8bd45c3f622c6900712cef46daf0e5ca7e0f64d4ae082
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

+++++++++++++++++
#if you need to reset the cluster
sudo kubeadm reset
+++++++++++++++++

#Start using kubectl command
kubectl get nodes

#output
amrutagosavi76a@ip-172-31-21-114:~$ kubectl get nodes
NAME               STATUS     ROLES                  AGE     VERSION
ip-172-31-21-114   NotReady   control-plane,master   6m49s   v1.23.2
amrutagosavi76a@ip-172-31-21-114:~$ 

#Install network componet 
#canal
#flannel
#calico

#Get the file from github and use the to install k8s network, we are going to use flannel
https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml

#Creat a file kube-flannel.yml
nano kube-flannel.yml

copy the content and paste the same

#Now apply the kube-flannel.yml using kubectl command
kubectl apply -f kube-flannel.yml

############output########
mrutagosavi76a@ip-172-31-21-114:~$ kubectl apply -f kube-flannel.yml
namespace/kube-flannel created
clusterrole.rbac.authorization.k8s.io/flannel created
clusterrolebinding.rbac.authorization.k8s.io/flannel created
serviceaccount/flannel created
configmap/kube-flannel-cfg created
daemonset.apps/kube-flannel-ds created
amrutagosavi76a@ip-172-31-21-114:~$ 
############################
#check the status of the node again now it should be ready
amrutagosavi76a@ip-172-31-21-114:~$ kubectl get nodes
NAME               STATUS   ROLES                  AGE   VERSION
ip-172-31-21-114   Ready    control-plane,master   14m   v1.23.2
amrutagosavi76a@ip-172-31-21-114:~$
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
EKS Installation eksctl tool

1. Prequisite would Be AWS CLI tool should be installed.
    7  sudo apt  install awscli
    8  clear
    9  aws configure


AWS Access Key ID [None]:
AWS Secret Access Key [None]:
Default region name [None]: ap-south-1
Default output format [None]:

2. Kubectl tool should be installed
https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html

  15  curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.23.17/2023-05-11/bin/linux/amd64/kubectl
   16  ls
   17  curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.23.17/2023-05-11/bin/linux/amd64/kubectl.sha256
   18  ls
   19  sha256sum -c kubectl.sha256
   20  openssl sha1 -sha256 kubectl
   21  clear
   22  ls
   23  chmod +x ./kubectl
   24  ls
   25  mkdir -p $HOME/bin && cp ./kubectl $HOME/bin/kubectl && export PATH=$HOME/bin:$PATH
   26  ls
   27  echo 'export PATH=$HOME/bin:$PATH' >> ~/.bashrc
   28  kubectl version --short --client


3. eksctl tool should be installed
https://docs.aws.amazon.com/eks/latest/userguide/getting-started-eksctl.html

# for ARM systems, set ARCH to: `arm64`, `armv6` or `armv7`
ARCH=amd64
PLATFORM=$(uname -s)_$ARCH

curl -sLO "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"

# (Optional) Verify checksum
curl -sL "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_checksums.txt" | grep $PLATFORM | sha256sum --check

tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp && rm eksctl_$PLATFORM.tar.gz

sudo mv /tmp/eksctl /usr/local/bin
eksctl version


To create the EKS cluster:
eksctl create cluster --name aws-eks-startagile --region ap-south-1 --version 1.23 --nodegroup-name kube-nodes --node-type t2.micro --node-ami-family=Ubuntu2004 --nodes 2

#to delete the cluster and nodes
eksctl delete cluster --name aws-eks-startagile --region ap-south-1




